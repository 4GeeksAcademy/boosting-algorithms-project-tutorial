<!-- hide -->
# Boosting algorithm Project Tutorial
<!-- endhide -->

- Hasta ahora, hemos modelado datos del Titanic con regresi√≥n log√≠stica y con Random Forest. En este proyecto continuaremos con la parte de modelado del Titanic creando un √∫ltimo modelo con un algoritmo de aumento de gradiente: XGBoost

## üå± C√≥mo iniciar este proyecto

Esta vez no crear√°s un nuevo repositorio. Contin√∫a con tu proyecto Titanic creando una nueva pieza de modelado para XGBoost (despu√©s de los resultados de Random Forest).

## üöõ C√≥mo entregar este proyecto

Una vez que hayas terminado de crear tu modelo, aseg√∫rate de confirmar tus cambios, presiona tu repositorio y ve a 4Geeks.com para cargar el enlace del repositorio nuevamente (el mismo enlace que entreg√≥ en el proyecto anterior).

## üìù Instrucciones:

**Predicci√≥n de la supervivencia del Titanic usando XGBoost**

Necesitamos construir un modelo predictivo que responda a la pregunta: "¬øqu√© tipo de personas ten√≠an m√°s probabilidades de sobrevivir?" utilizando datos de pasajeros (es decir, nombre, edad, sexo, clase socioecon√≥mica, etc.). Para poder predecir qu√© pasajeros ten√≠an m√°s probabilidades de sobrevivir, usaremos XGBoost para entrenar el modelo.

**Paso 1:**

Crea un nuevo modelo predictivo (no borres el anterior) usando XGBoost. 

**Paso 2:**

Usando la misma m√©trica de evaluaci√≥n que el √∫ltimo proyecto, eval√∫a tu nuevo modelo XGBoost.
Optimiza los hiperpar√°metros de tu modelo. La lista completa de posibles par√°metros se puede encontrar en el siguiente enlace: https://xgboost.readthedocs.io/en/latest/parameter.html

**Paso 3:**

Usa app.py para crear tu nuevo pipeline.

Guarda tu modelo XGBoost final en la carpeta 'models'.

En tu archivo README escribe un breve resumen.